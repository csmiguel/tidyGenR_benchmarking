---
author: Miguel Camacho SÃ¡nchez
title: "tidyGenR benchmarking"
editor: visual
theme: minty
format:
  html:
    toc: true
    code-tools: true
---

Attach libraries:
```{r}
#| echo: false
#| include: false
knitr::opts_knit$set(root.dir = "../")
```

```{r attach packages}
#| message: false
#| warning: false
library(tidyGenR)
library(dplyr)
library(patchwork)
library(ggplot2)
```

```{r eval_conditionals}
#| echo: false
#| eval: true
# declare logicals to trigger EVAL in intensive code chunks
# they are not run if output already exists.
# to run a fresh analysis outputs need to be removed.
# demultiplex
c_log <- "output/cutadapt.log"
eval_demultiplex <- !file.exists(c_log)
# truncate
tr_path <- "output/trunc_in-out.rds"
eval_truncate <- !file.exists(tr_path)
# explore_dada
x_out_path <- "output/explore_dada.rds"
eval_x <- !file.exists(x_out_path)
# variant_call
x_variants_path <-  "output/variants_x.rds"
eval_variant_call <- !file.exists(x_variants_path)
# genotype
x_genotypes_path <-  "output/genotypes_x.rds"
eval_genotype <- !file.exists(x_genotypes_path)
# amplisas
amplisas_results <- ""
eval_amplisas <- !file.exists(amplisas_results)
```

## Benchmarking *tidyGenR*

This repository accompanies the R package **tidyGenR** available at <https://github.com/csmiguel/tidyGenR>. It covers (1) all steps for genotype calling with *tidyGenR*, (2) exploration of the parameters for variant calling, and (3) comparison of *tidyGenR* against [AmpliSAS](https://doi.org/10.1111/1755-0998.12453). It uses real data from a population genetics study of the wild rodent *Rattus baluensis* (Camacho-Sanchez et al. *in preparation*).

## Preparation of input data

Raw sequences are deposited in NCBI under the BioStudy [SRP293699](https://trace.ncbi.nlm.nih.gov/Traces/study/?acc=SRP293699), in the BioProject [PRJNA680166](https://www.ncbi.nlm.nih.gov/bioproject/PRJNA680166). From the BioStudy, we can download the [SRA metadata](data/raw/SraRunTable.csv) to map sample IDs to SRRs:

```{r SRR}
# table with mapped SRR-sampleIDs
srr <-
  read.csv("data/raw/SraRunTable.csv") |>
  select(Run, "Sample.Name") |>
  rename(run = Run,
         sample = "Sample.Name")
knitr::kable(head(srr, 3))
```

The FASTQ reads from the SRRs can be downloaded with [SRA-toolkit](https://github.com/ncbi/sra-tools):

```{r download_raw_data}
#|  message: false
#|  warning: false
#|  error: false
#|  code-fold: true
# download raw reads from NCBI
# they are not downloaded if already present in 'data/raw'.
apply(srr, 1, function(x) {
  # name paths
  srr_path <- file.path("data/raw", x[1])
  srr1 <- file.path("data/raw", paste0(x[1], "_1.fastq"))
  srr2 <- file.path("data/raw", paste0(x[1], "_2.fastq"))
  sam1 <- file.path("data/raw", paste0(x[2], "_1.fastq"))
  sam2 <- file.path("data/raw", paste0(x[2], "_2.fastq"))
  # fetch SRR
  if (!any(dir.exists(srr_path) || file.exists(sam1))) {
    system2("prefetch", paste("-O", "data/raw/", x[1]))
  }
  # reformat to FASTQ
  if (!file.exists(sam1)) {
    system2("fasterq-dump", paste("-O", "data/raw/", srr_path))
    system2("mv", paste(srr1, sam1))
    system2("mv", paste(srr2, sam2))
    # rm SRR
    system2("rm", paste0("-r ", srr_path, "*"))
  }
  })
# glimpse raw FASTQ
list.files("data/raw", pattern = "fastq")[1:3]
```

Check input data files:

```{r check_raw_reads}
freads <- list.files("data/raw", pattern = "1.fastq",
                    full.names = TRUE)
rreads <- list.files("data/raw", pattern = "2.fastq",
                    full.names = TRUE)
chr <- check_raw_reads(freads, rreads, low_readcount = 10)
```

Input FASTQ is conditions for *tidyGenR*. A total of `r length(chr$samples)` are detected:

```{r}
chr$samples
```

## Demultiplex by locus

Reads are demultiplexed by locus using primer sequences in paired-end mode.

```{r demultiplex_objects}
#| warning: false
# load primer data
data("primers")
# path to cutadapt
cutadapt <- system("which cutadapt", intern = TRUE)
# path to folder save locus-demultiplexed FASTQ
demult <- "data/intermediate/demultiplexed"
# print primers
knitr::kable(head(primers, 3))
```

```{r demultiplex}
#| eval: !expr eval_demultiplex
#| warning: false
# demultiplex
demultiplex(
  interpreter = "/bin/bash",
  cutadapt = cutadapt,
  freads = freads,
  rreads = rreads,
  primers = primers,
  sh_out = "code/demultiplex.sh",
  write_demultiplexed = demult,
  log_out = c_log,
  mode = "pe",
  run = TRUE)
```

```{r}
# glimpse demultiplexed FASTQ
list.files(demult, pattern = "fastq")[1:3]
```

Remove files with few reads:

```{r rm_after_dem}
#| warning: false
remove_poor_fastq(demult,
                   min_reads = 10)
```

## Truncate reads

Reads are truncated to a given length for each locus. A `data.frame` with truncation lengths for forward and reverse reads was built to maximize the amount of information yielded by each locus. For instance, the amplicons for some loci, as *nfkbia*, are long and it is a good trade-off to leave the low quality ends in but to be sure both F and R reads overlap.

Building of `data.frame` with locus-specific truncation lengths:

```{r build_trunc_fr}
#| message: false
#| include: false
loci <- 
  tidyGenR:::check_names_demultiplexed(demult,
                                     fw_pattern = "1.fastq.gz",
                                     rv_pattern = "2.fastq.gz")$loci

trunc_fr <-
  data.frame(locus = loci,
             trunc_f = 270,
             trunc_r = 180)
# introduce manual values
trunc_fr[which(loci == "rgd735029"), "trunc_f"] <-  245
trunc_fr[which(loci == "rgd735029"), "trunc_r"] <-  155
trunc_fr[which(loci == "fancg"), "trunc_r"] <- 190
trunc_fr[which(loci == "nfkbia"), "trunc_r"] <- 240
trunc_fr[which(loci == "tmem87a"), "trunc_r"] <- 160

# glimpse data.frame with locus-specific truncation lengths
knitr::kable(head(trunc_fr, 3))
```

Truncate reads according to locus-specific truncation lengths:

```{r declare_tr_dir}
tr_dir <- "data/intermediate/truncated"
```

```{r truncate}
#| message: false
#| warning: false
#| eval: !expr eval_truncate

# truncate
trunc_out <-
  trunc_amp(in_dir = demult,
          fw_pattern = "1.fastq.gz",
          rv_pattern = "2.fastq.gz",
          trunc_fr = trunc_fr,
          write_trun = tr_dir,
          max_ee = c(4, 5),
          trunc_q = 2)
# save reads in and out
saveRDS(trunc_out, tr_path)
```

The output from `trunc_amp()` is a list of matrices with IN and OUT reads after truncation:

```{r}
#| echo: false
trunc_out <- readRDS(tr_path)
remove_poor_fastq(tr_path,
                   min_reads = 10)
```

```{r}
# see trunc_out
lapply(trunc_out[seq_len(3)], head, 3)
```

## Exploration of the parameter space

The function `explore_dada()` can be used to explore the effect of DADA2 parameters ("OMEGA_A", "BAND_SIZE", "pool") on the sensitivity on the variant calling.

-   *omega_a*: threshold for variants to be significant overabundant *log(-log(birth_pval))* (see [Rosen et al. 2012](https://doi.org/10.1186/1471-2105-13-283.)).
-   *band_size*: positive numbers set a band size in Needleman-Wunsch alignments. In this context, ends free alignment is performed. A value of zero turns off banding, triggering full Needleman-Wunsch alignments, in which gapless alignment is performed (see [issue](https://github.com/benjjneb/dada2/issues/1982)).
-   *pool*: calling variants pooling samples can increase sensitivity (see [dicussion](https://benjjneb.github.io/dada2/pseudo.html)).

The returned plots can be used to guide the election of the best *OMEGA_A* in `variant_call()`, or frequency (*maf*) and abundance thresholds (*ad*) for filtering variants.

Explore variants:

```{r}
# declare candidate OMEGA_A to use in variant_call()
candidate_omega_a <- 10^-2
```

```{r explore_dada}
#| eval: !expr eval_x
#| message: false
# paths to forward and reverse truncated reads
ftrun <-
  list.files(tr_dir, pattern = "_F_", full.names = T)
rtrun <-
  list.files(tr_dir, pattern = "_R_", full.names = T)
# candidate omegavalue to annotate vline in plots.
v_line <- log(-log(candidate_omega_a))
# run explore_dada() with band_size = 0, non pooling and omega_a = 0.9
# forward
F_ind_0 <-
  explore_dada(ftrun, band_size = 0, vline = v_line, hline_fr = 0.1)
# reverse
R_ind_0 <-
  explore_dada(rtrun, band_size = 0, vline = v_line, hline_fr = 0.1)
# save results
saveRDS(list(F_ind_0 = F_ind_0, R_ind_0 = R_ind_0), x_out_path)
```

Exploration of DADA2 clustering for forward (A, C) and reverse (B, D) reads. The Y-axis represents the frequency of the variant in each locus and sample. The *log(-log(birth_pval))* transformation in the X-axis is related to the p-value of a variant being significantly overabundant. Larger x-values represent likely true variants. For representation purposes *birth_pval* of 0 (thus negative infinite), are converted to 10. Points are color-coded according to the variant rank in read abundance for its given locus and sample. For diploid individuals, [green]{style="color: green;"} are likely true variants and [red]{style="color: red;"} are likely false variants. [Grey]{style="color: grey;"} dashed lines are thresholds used for `variant_call()`:

```{r x_attach_if_not_run}
#| echo: false
#| eval: true
if (!(exists("F_ind_0") || exists("R_ind_0"))) {
    x_dada <- readRDS(x_out_path)
    attach(x_dada)
}
```

```{r plot_explore_dada}
#| label: fig-explore_dada
#| warnings: false
#| fig-cap: "Exploration of DADA2 variants"
#| code-fold: true
ppool <-
  (F_ind_0$p1 | R_ind_0$p1) / (F_ind_0$p2 | R_ind_0$p2) +
  patchwork::plot_annotation(title = "Dada F/R pool = F, omega_a 0.9, band_size = 0",
                             tag_levels = "A")
# save plot with combined loci
ggsave("output/explore_dada.pdf", ppool, width = 8, height = 5)
# print plot
ppool
```

After the exploration variants in @fig-explore_dada, it seems an *OMEGA_A* = `r candidate_omega_a`, implying a cutoff of `r log(-log(candidate_omega_a))` in the X-axis and a frequency threshold (Y-axis) of 0.1, excludes most [artifacts]{style="color: red;"} while maximizing [true positives]{style="color: green;"}.

The results can also be explored **per-locus**. For instance, @fig-explore_dada B can be expanded per locus as follows:

```{r}
#| include: false
#| message: false
#| code-fold: true
# list of plots per locus
lplots <-
  list(loci_f_ind_0_logp = F_ind_0$p3,
       loci_r_ind_0_logp = R_ind_0$p3,
       loci_f_ind_0_abun = F_ind_0$p4,
       loci_r_ind_0_abun = R_ind_0$p4)

# save plots per locus
lapply(seq_along(lplots), function(x) {
  ggsave(paste0("output/", names(lplots)[x], ".pdf"),
         lplots[[x]], width = 6, height = 6)
  })
```

```{r}
#| label: fig-explore_dada_loci
#| warnings: false
#| fig-cap: "Exploration of DADA2 variants per locus for R reads"
lplots$loci_r_ind_0_logp
```

## Variant and genotype calling

Variant calling is run using *OMEGA_A* = `r candidate_omega_a`, and under different parameters:

-   *band_size*: 0, 16
-   *pool*: TRUE, FALSE

```{r variant_call}
#| message: false
#| eval: !expr eval_variant_call
#| include: false
# list of parameters to run variant_call() with 4 different set of values:
variant_call_params <-
  list(
    ind_bs16 = c(FALSE, 16), # pool = F, default band size == 16
    ind_bs0 = c(FALSE, 0), # pool = F, default band size == 0
    pool_bs16 = c(TRUE, 16), # pool = T, default band size == 16
    pool_bs0 = c(TRUE, 0) # pool = T, default band size == 0
)

variants_x <-
  lapply(variant_call_params, function(x) {
    variant_call(in_folder = tr_dir,
                 rv_pattern = "R_filt.fastq.gz",
                 c_unmerged = TRUE,
                 multithread = TRUE,
                 pool = as.logical(x[1]),
                 omega_a_f = candidate_omega_a,
                 omega_a_r = candidate_omega_a,
                 band_size = x[2],
                 ad = 10,
                 maf = 0.1)
  })
saveRDS(variants_x, "output/variants_x.rds")
```

```{r}
#| echo: false
if (!exists("variants_x"))
  variants_x <- readRDS("output/variants_x.rds")
```

Variants are used to genotype individuals with defaults `ploidy = 2` and `ADt = 10`:

```{r}
#| message: false
#| eval: !expr eval_genotype
genotypes_x <-
  lapply(variants_x, genotype)
saveRDS(genotypes_x, file = "output/genotypes_x.rds")
```

```{r}
#| echo: false
if (!exists("genotypes_x"))
  genotypes_x <- readRDS("output/genotypes_x.rds")
```

## Tidy data

A strong point from *tidyGenR* is that variants and genotypes from `variant_call()` and `genotype()` are returned in `tidy` format: one row per observation and variables in columns. Lets have a look at the data structure.

```{r glimpse_tidy_variants}
# glimpse tidy variants
knitr::kable(head(variants_x$ind_bs0))
```

```{r glimpse_tidy_genotypes}
# glimpse tidy genotypes
knitr::kable(head(genotypes_x$ind_bs0))
```

## *tidyGenR* vs AmpliSAS

[AmpliSAS](https://doi.org/10.1111/1755-0998.12453) is a software written in PERL with similar characteristics to *tidyGenR*. To compare their performance we run AmpliSAS in a docker container to genotype our raw sequences. The steps are detailed [here](code/amplisas). AmpliSAS returns results in a multisheet EXCEL and in plain text files, one per locus. The function `amplisas2tidy()` permits to read plain text results from AmpliSAS into tidy variants.

Create input for AmpliSAS:

```{r}
#| eval: false
# amplicon metadata
source("code/amplisas/01_create_amplicon_data.R")
# append barcodes to reads
source("code/amplisas/02_add_barcodes.R")

```

AmpliSAS is run in a DOCKER container. The steps are detailed [here](amplisas/benchmarking.md).

# Integration of alleles with publised data

```{r}

```

# session info

Details on the sessionInfo() are [here](session_info.txt):

```{r}
writeLines(capture.output(sessionInfo()), con = "session_info.txt")
```
